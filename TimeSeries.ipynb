{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnovaYoung/IoT_PhysicalTherapy/blob/main/TimeSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdPKvVGEOeGt"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "zip_file_path = '/Users/anovayoungers/Downloads/physical+therapy+exercises+dataset.zip'\n",
        "\n",
        "extraction_directory = '/Users/anovayoungers/Downloads/physical_therapy_dataset'\n",
        "\n",
        "with ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_directory)\n",
        "\n",
        "    print(f'Files Extracted to {extraction_directory}')\n",
        "\n",
        "for root, dirs, files in os.walk(extraction_directory, topdown=True):\n",
        "    for name in files:\n",
        "        print(os.path.join(root, name))\n",
        "    for name in  dirs:\n",
        "        print(os.path.join(root, name))\n",
        "\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load data from a specified file path into a pandas DataFrame.\"\"\"\n",
        "    try :\n",
        "        data = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error Loading Data: {e} \")\n",
        "        return None\n",
        "\n",
        "file_path = '/Users/anovayoungers/Downloads/physical_therapy_dataset/s1/e1/u1/test.txt'\n",
        "data = load_data(file_path)\n",
        "\n",
        "def load_data_from_directory(directory_path):\n",
        "    sensor_data = []\n",
        "    session_metadata = []\n",
        "    times_metadata = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory_path, topdown=True):\n",
        "        parts = root.split(os.sep)\n",
        "        subject = next((part for part in parts if part.startswith('s')), None)\n",
        "        exercise = next((part for part in parts if part.startswith('e')), None)\n",
        "        sensor_unit = next((part for part in parts if part.startswith('u')), None)\n",
        "\n",
        "        for name in files:\n",
        "            file_path = os.path.join(root, name)\n",
        "            if name == 'test.txt':\n",
        "                data = pd.read_csv(file_path, sep=\";\", header=0)\n",
        "                data['subject'] = subject\n",
        "                data['exercise'] = exercise\n",
        "                data['sensor_unit'] = sensor_unit\n",
        "                sensor_data.append(data)\n",
        "            elif name == 'template_session.txt':\n",
        "                session_data = pd.read_csv(file_path, sep=\";\", header=0)\n",
        "                session_data['subject'] = subject\n",
        "                session_data['exercise'] = exercise\n",
        "                session_data['sensor_unit'] = sensor_unit\n",
        "                session_metadata.append(session_data)\n",
        "            elif name == 'template_times.txt':\n",
        "                times_data = pd.read_csv(file_path, sep=\";\", header=0)\n",
        "                times_data['subject'] = subject\n",
        "                times_data['exercise'] = exercise\n",
        "\n",
        "                times_metadata.append(times_data)\n",
        "\n",
        "    sensor_df = pd.concat(sensor_data, ignore_index=True)\n",
        "    session_df = pd.concat(session_metadata, ignore_index=True)\n",
        "    times_df = pd.concat(times_metadata, ignore_index=True)\n",
        "\n",
        "    return sensor_df, session_df, times_df\n",
        "\n",
        "extraction_directory = '/Users/anovayoungers/Downloads/physical_therapy_dataset'\n",
        "sensor_df, session_df, times_df = load_data_from_directory(extraction_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cmoh0C0UOeGv",
        "outputId": "571a2934-1f60-42d0-8b91-d1fbbe098af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   execution type  start    end subject exercise\n",
            "0               1  168.0  267.0      s5       e5\n",
            "1               2  519.0  588.0      s5       e5\n",
            "2               3  805.0  890.0      s5       e5\n",
            "3               1  175.0  315.0      s5       e2\n",
            "4               2  595.0  671.0      s5       e2\n"
          ]
        }
      ],
      "source": [
        "print(times_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8mN-onmOeGw",
        "outputId": "c9a0a9a3-6f67-4084-91d5-f2866230f67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    time index     acc_x     acc_y     acc_z     gyr_x     gyr_y     gyr_z  \\\n",
            "0            1  1.141452  9.587617  1.343498 -0.070101  0.005029 -0.011399   \n",
            "1            2  1.164059  9.602035  1.463472 -0.034009  0.010527 -0.011461   \n",
            "2            3  1.164136  9.639337  1.478518  0.002012 -0.015333 -0.011723   \n",
            "3            4  1.194045  9.661973  1.374475  0.020135 -0.000033 -0.011679   \n",
            "4            5  1.178997  9.647259  1.329349  0.025554  0.001804 -0.010769   \n",
            "..         ...       ...       ...       ...       ...       ...       ...   \n",
            "95          96  1.296696  9.564875 -0.910514  0.014767 -0.008208  0.023501   \n",
            "96          97  1.206768  9.482702 -0.792701  0.084830 -0.012439 -0.021883   \n",
            "97          98  1.222116  9.939922 -1.239535  0.156035  0.006158 -0.002965   \n",
            "98          99  1.266282  9.491561 -1.269886  0.005385  0.003686 -0.008040   \n",
            "99         100  1.131626  9.536581 -1.145015  0.013635 -0.015405 -0.024414   \n",
            "\n",
            "       mag_x     mag_y     mag_z subject exercise sensor_unit  execution_type  \n",
            "0  -0.445307 -0.798925 -0.107220      s5       e5          u1             NaN  \n",
            "1  -0.446360 -0.797980 -0.108362      s5       e5          u1             NaN  \n",
            "2  -0.445484 -0.798622 -0.111318      s5       e5          u1             NaN  \n",
            "3  -0.444755 -0.797540 -0.110497      s5       e5          u1             NaN  \n",
            "4  -0.444055 -0.797550 -0.108431      s5       e5          u1             NaN  \n",
            "..       ...       ...       ...     ...      ...         ...             ...  \n",
            "95 -0.446980 -0.804788  0.092000      s5       e5          u1             NaN  \n",
            "96 -0.445973 -0.806284  0.094241      s5       e5          u1             NaN  \n",
            "97 -0.447663 -0.804945  0.093751      s5       e5          u1             NaN  \n",
            "98 -0.447504 -0.804556  0.095929      s5       e5          u1             NaN  \n",
            "99 -0.446622 -0.802964  0.100695      s5       e5          u1             NaN  \n",
            "\n",
            "[100 rows x 14 columns]\n"
          ]
        }
      ],
      "source": [
        "print(sensor_df.head(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0tqja3qOeGw",
        "outputId": "39d7f856-b54c-4b64-de0b-e2a7e9039cae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 120 entries, 0 to 119\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   execution type  120 non-null    int64  \n",
            " 1   start           120 non-null    float64\n",
            " 2   end             120 non-null    float64\n",
            " 3   subject         120 non-null    object \n",
            " 4   exercise        120 non-null    object \n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 4.8+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(times_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7npRl-8OeGw",
        "outputId": "9dcfc9a7-79ab-4f15-b404-547876b86cb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1101390 entries, 0 to 1101389\n",
            "Data columns (total 13 columns):\n",
            " #   Column       Non-Null Count    Dtype  \n",
            "---  ------       --------------    -----  \n",
            " 0   time index   1101390 non-null  int64  \n",
            " 1   acc_x        1101390 non-null  float64\n",
            " 2   acc_y        1101390 non-null  float64\n",
            " 3   acc_z        1101390 non-null  float64\n",
            " 4   gyr_x        1101390 non-null  float64\n",
            " 5   gyr_y        1101390 non-null  float64\n",
            " 6   gyr_z        1101390 non-null  float64\n",
            " 7   mag_x        1101390 non-null  float64\n",
            " 8   mag_y        1101390 non-null  float64\n",
            " 9   mag_z        1101390 non-null  float64\n",
            " 10  subject      1101390 non-null  object \n",
            " 11  exercise     1101390 non-null  object \n",
            " 12  sensor_unit  1101390 non-null  object \n",
            "dtypes: float64(9), int64(1), object(3)\n",
            "memory usage: 109.2+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(sensor_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wD7RD65_OeGw",
        "outputId": "b6c9f2d2-9812-4d32-9fec-bdb726a13f6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input sequence: [[[1.141452 9.587617 1.343498]\n",
            "  [1.164059 9.602035 1.463472]\n",
            "  [1.164136 9.639337 1.478518]\n",
            "  [1.194045 9.661973 1.374475]\n",
            "  [1.178997 9.647259 1.329349]\n",
            "  [1.163999 9.662428 1.284303]\n",
            "  [1.194028 9.692118 1.299835]\n",
            "  [1.17904  9.684691 1.307034]\n",
            "  [1.164054 9.647173 1.373928]\n",
            "  [1.156551 9.632215 1.388705]]], Target value: [1.164066]\n",
            "Input sequence: [[[1.164059 9.602035 1.463472]\n",
            "  [1.164136 9.639337 1.478518]\n",
            "  [1.194045 9.661973 1.374475]\n",
            "  [1.178997 9.647259 1.329349]\n",
            "  [1.163999 9.662428 1.284303]\n",
            "  [1.194028 9.692118 1.299835]\n",
            "  [1.17904  9.684691 1.307034]\n",
            "  [1.164054 9.647173 1.373928]\n",
            "  [1.156551 9.632215 1.388705]\n",
            "  [1.164066 9.662167 1.359025]]], Target value: [1.179049]\n",
            "Input sequence: [[[1.164136 9.639337 1.478518]\n",
            "  [1.194045 9.661973 1.374475]\n",
            "  [1.178997 9.647259 1.329349]\n",
            "  [1.163999 9.662428 1.284303]\n",
            "  [1.194028 9.692118 1.299835]\n",
            "  [1.17904  9.684691 1.307034]\n",
            "  [1.164054 9.647173 1.373928]\n",
            "  [1.156551 9.632215 1.388705]\n",
            "  [1.164066 9.662167 1.359025]\n",
            "  [1.179049 9.662096 1.359278]]], Target value: [1.179022]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import numpy as np\n",
        "\n",
        "data = sensor_df[['acc_x', 'acc_y', 'acc_z']].values # Input data\n",
        "target = sensor_df['acc_x'].values  # Target variable\n",
        "\n",
        "n_input = 10\n",
        "generator = TimeseriesGenerator(data, target, length=n_input, batch_size=1)\n",
        "\n",
        "for i in range(len(generator)):\n",
        "    x, y = generator[i]\n",
        "    print(f'Input sequence: {x}, Target value: {y}')\n",
        "    if i >= 2:  # Stops after 2 batches\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmq_hX2VOeGw",
        "outputId": "5c675a59-cc5b-403b-e852-46a5ed4fb75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1101380/1101380 [==============================] - 1237s 1ms/step - loss: 1.5211 - val_loss: 54.4043\n",
            "Epoch 2/10\n",
            "1101380/1101380 [==============================] - 1238s 1ms/step - loss: 29.6963 - val_loss: 52.1510\n",
            "Epoch 3/10\n",
            "1101380/1101380 [==============================] - 1233s 1ms/step - loss: 0.2780 - val_loss: 54.5494\n",
            "Epoch 4/10\n",
            "1101380/1101380 [==============================] - 1495s 1ms/step - loss: 10.3007 - val_loss: 52.7331\n",
            "Epoch 5/10\n",
            "1101380/1101380 [==============================] - 1571s 1ms/step - loss: 0.1849 - val_loss: 49.1595\n",
            "Epoch 6/10\n",
            "1101380/1101380 [==============================] - 1590s 1ms/step - loss: 0.2763 - val_loss: 50.5445\n",
            "Epoch 7/10\n",
            "1101380/1101380 [==============================] - 1587s 1ms/step - loss: 0.2467 - val_loss: 50.8342\n",
            "Epoch 8/10\n",
            "1101380/1101380 [==============================] - 1865s 2ms/step - loss: 0.2998 - val_loss: 52.3259\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2eb961490>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(data, target, test_size=0.2, random_state=42)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "train_generator = TimeseriesGenerator(X_train, y_train, length=n_input, batch_size=1)\n",
        "val_generator = TimeseriesGenerator(X_val, y_val, length=n_input, batch_size=1)\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(50, activation='relu', input_shape=(n_input, 3)),  # the 3 features: acc_x, acc_y, acc_z\n",
        "    Dense(1)  # This means predict the next value of acc_x\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model.fit(generator, epochs=10, batch_size=256, verbose=1, callbacks=[early_stopping], validation_data=val_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Wx6gl-VOeGx",
        "outputId": "681fc95c-bfae-4f35-faaa-c21154999a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110129/110129 [==============================] - 49s 447us/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(val_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K02bPI9sOeGx",
        "outputId": "653027c4-82e1-434e-d987-037ac401b6d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110139 110129\n"
          ]
        }
      ],
      "source": [
        "print(len(y_val), len(predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faRg-fScOeGx",
        "outputId": "c36421d8-0fbb-489a-c577-f59c4727ca53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "110129 110129\n"
          ]
        }
      ],
      "source": [
        "# Truncate y_val to match the length of predictions\n",
        "y_val_aligned = y_val[:len(predictions)]\n",
        "\n",
        "print(len(y_val_aligned), len(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vd10n_hOeGx"
      },
      "outputs": [],
      "source": [
        "actual_vs_predicted = pd.DataFrame({\n",
        "    'Actual': y_val_aligned,\n",
        "    'Predicted': predictions.flatten()\n",
        "})\n",
        "\n",
        "actual_vs_predicted['Index'] = range(len(actual_vs_predicted))\n",
        "\n",
        "actual_vs_predicted.to_csv('/Users/anovayoungers/Downloads/actual_vs_predicted.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}